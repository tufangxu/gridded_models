import yaml
import psycopg2
from psycopg2.extensions import AsIs
import os.path
import subprocess
from urllib.request import urlretrieve
import glob
from osgeo import gdal
import re
import datetime
import osr
from util.raster import *
from util.database import *


with open(os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir, 'config.yml')), 'r') as ymlfile:
    cfg = yaml.load(ymlfile)

save_path = cfg["ndfd_path"]


def download_forecast():
    # download next 7 days of min and max temp predictions starting with tomorrow
    # two files are provided with 3 bands in the first and 4 bands in the second
    # each band represents a day
    url_tmax1 = 'http://weather.noaa.gov/pub/SL.us008001/ST.opnl/DF.gr2/DC.ndfd/AR.conus/VP.001-003/ds.maxt.bin'
    url_tmax2 = 'http://weather.noaa.gov/pub/SL.us008001/ST.opnl/DF.gr2/DC.ndfd/AR.conus/VP.004-007/ds.maxt.bin'
    url_tmin1 = 'http://weather.noaa.gov/pub/SL.us008001/ST.opnl/DF.gr2/DC.ndfd/AR.conus/VP.001-003/ds.mint.bin'
    url_tmin2 = 'http://weather.noaa.gov/pub/SL.us008001/ST.opnl/DF.gr2/DC.ndfd/AR.conus/VP.004-007/ds.mint.bin'

    forecasts = ({'url': url_tmax1, 'file_name': 'maxt1-3.bin'},
                 {'url': url_tmax2, 'file_name': 'maxt4-7.bin'},
                 {'url': url_tmin1, 'file_name': 'mint1-3.bin'},
                 {'url': url_tmin2, 'file_name': 'mint4-7.bin'})

    os.makedirs(save_path, exist_ok=True)

    # delete any files from previous last imports
    for bin_file in glob.glob(save_path + "*.bin"):
        os.remove(bin_file)
    for bil_file in glob.glob(save_path + "*.bil"):
        os.remove(bil_file)
    for xml_file in glob.glob(save_path + "*.xml"):
        os.remove(xml_file)
    for hdr_file in glob.glob(save_path + "*.hdr"):
        os.remove(hdr_file)

    for forecast in forecasts:
        print('retrieving ' + save_path + forecast['file_name'])
        urlretrieve(forecast['url'], save_path + forecast['file_name'])


def extract_bands():
    for bin_file in glob.glob(save_path + "*.bin"):
        forecast_data = gdal.Open(bin_file)
        num_bands = forecast_data.RasterCount
        for band in range(1, num_bands+1):
            data_band = forecast_data.GetRasterBand(band)
            meta = data_band.GetMetadata()
            element = meta['GRIB_ELEMENT']
            timestamp = re.findall('\d+', meta['GRIB_VALID_TIME'])[0]


            dest_file = save_path + element + '_' + timestamp + '.bin'
            extract_command = "gdal_translate -b {band_number} {source_file} {dest_file}"\
                .format(band_number=band, source_file=bin_file, dest_file=dest_file)
            ps = subprocess.Popen(extract_command, stdout=subprocess.PIPE, shell=True)
            ps.wait()
        os.remove(bin_file)


def set_projection_and_mask():
    # Define target SRS as EPSG 4269
    dst_srs = osr.SpatialReference()
    dst_srs.ImportFromEPSG(4269)
    dst_wkt = dst_srs.ExportToWkt()

    error_threshold = 0.125  # error threshold --> use same value as in gdalwarp
    resampling = gdal.GRA_Bilinear #GRA_NearestNeighbour

    for bin_file in glob.glob(save_path + "*.bin"):
        # Call AutoCreateWarpedVRT() to fetch default values for target raster dimensions and geotransform

        src_ds = gdal.Open(bin_file)
        tmp_ds = gdal.AutoCreateWarpedVRT( src_ds,
                                           None, # src_wkt : left to default value --> will use the one from source
                                           dst_wkt,
                                           resampling,
                                           error_threshold )

        # Create the final warped raster
        dst_ds = gdal.GetDriverByName('GTiff').CreateCopy('warp_test.tif', tmp_ds)
        band = dst_ds.GetRasterBand(1)
        temps_array = band.ReadAsArray()

        projection = dst_ds.GetProjection()
        transform = dst_ds.GetGeoTransform()

        # mask out non land areas
        apply_usa_mask(temps_array)

        # write masked file to disk
        write_raster(str.replace(bin_file, ".bin", ".tif"), temps_array, -9999, temps_array.shape[1], temps_array.shape[0], projection, transform)
        os.remove(bin_file)


def import_rasters():
    for ndfd_file in glob.glob(save_path + "*.tif"):
        if "MaxT" in ndfd_file:
            table_name = "ndfd_tmax"
        elif "MinT" in ndfd_file:
            table_name = "ndfd_tmin"

        forecast_unixtime = re.findall('\d+', ndfd_file)[0]
        forecast_date = datetime.datetime.fromtimestamp(int(forecast_unixtime)) #.strftime('%Y-%m-%d')

        ndfd_import(ndfd_file, table_name, forecast_date)
        os.remove(ndfd_file)


def ndfd_import(rast_path, table_name, date):
    curs = conn.cursor()
    new_table = not table_exists(table_name)

    save_raster_to_postgis(rast_path, table_name, None)

    if new_table:
        # create entry in mosaic table (for geoserver to work)
        add_mosaic_entry(table_name, -130.1228935, 52.8168964, -60.8601260, 20.1788770, 0.026578191679851, 0.026578191679851)

        # add rast_date
        query = "ALTER TABLE %(table)s ADD rast_date DATE;"
        curs.execute(query, {"table": AsIs(table_name)})
        query = "CREATE INDEX ON %(table)s (rast_date);"
        curs.execute(query, {"table": AsIs(table_name)})
        query = "CREATE INDEX ON %(table)s (filename);"
        curs.execute(query, {"table": AsIs(table_name)})
        conn.commit()

    query = "UPDATE %(table)s SET rast_date = to_date(%(rast_date)s, 'YYYYMMDD') WHERE rast_date IS NULL;"
    data = {"table": AsIs(table_name), "rast_date": date.strftime("%Y%m%d")}
    curs.execute(query, data)

    conn.commit()


def warp_to_prism():
    # reproject, crop, and rescale so that ndfd raster overlays prism raster nicely
    for bin_file in glob.glob(save_path + "*.bin"):
        warped_file = str.replace(bin_file, ".bin", ".bil")
        warp_command = "gdalwarp -of ENVI -srcnodata 9999 -dstnodata -9999 -t_srs EPSG:4269 -te -125.0208333 24.0625000 -66.4791667 49.9375000 -ts 1405 621 {source_file} {dest_file}"\
            .format(source_file=bin_file, dest_file=warped_file)
        ps = subprocess.Popen(warp_command, stdout=subprocess.PIPE, shell=True)
        ps.wait()


# def postgis_import():
#     for ndfd_file in glob.glob(save_path + "*.bil") + glob.glob(save_path + "*.bin"):
#         table_name = None
#         resolution = None
#         # the bil files are rescaled to 4k
#         # the bin files are the original 2.5k resolution
#         if ".bin" in ndfd_file:
#             resolution = '2.5k'
#             if "MaxT" in ndfd_file:
#                 table_name = "ndfd_tmax_2p5k"
#             elif "MinT" in ndfd_file:
#                 table_name = "ndfd_tmin_2p5k"
#         elif ".bil" in ndfd_file:
#             resolution = '4k'
#             if "MaxT" in ndfd_file:
#                 table_name = "ndfd_tmax_4k"
#             elif "MinT" in ndfd_file:
#                 table_name = "ndfd_tmin_4k"
#
#         new_table = True
#         query = "SELECT COUNT(*) FROM information_schema.tables WHERE table_name = %s;"
#         curs.execute(query, [table_name])
#         if curs.fetchone()[0] == 1:
#             new_table = False
#
#         # remove old entry if already exists
#         if not new_table:
#             query = "DELETE FROM %(table)s WHERE filename = %(filename)s;"
#             data = {"table": AsIs(table_name), "filename": os.path.basename(ndfd_file)}
#             curs.execute(query, data)
#             conn.commit()
#
#         # insert the raster (either create a new table or append to previously created table)
#         if new_table:
#             import_command = "raster2pgsql -s 4269 -c -I -C -M -F -t auto {file} public.{table}"\
#                 .format(file=ndfd_file, table=table_name)
#         else:
#             import_command = "raster2pgsql -s 4269 -a -M -F -t auto {file} public.{table}"\
#                 .format(file=ndfd_file, table=table_name)
#         import_command2 = "psql -h {host} -p {port} -d {database} -U {user} --no-password"\
#             .format(host=db["host"], port=db["port"], database=db["db"], user=db["user"])
#         ps = subprocess.Popen(import_command, stdout=subprocess.PIPE, shell=True)
#         subprocess.check_output(import_command2, stdin=ps.stdout, shell=True)
#         ps.wait()
#
#         # possibly set up extra table structure
#         if new_table:
#             query = "ALTER TABLE %(table)s ADD forecast_date date;"
#             curs.execute(query, {"table": AsIs(table_name)})
#             conn.commit()
#         forecast_unixtime = re.findall('\d+', ndfd_file)[0]
#         forecast_date = datetime.datetime.fromtimestamp(int(forecast_unixtime)).strftime('%Y-%m-%d')
#         query = "UPDATE %(table)s SET forecast_date = to_date(%(forecast_date)s, 'YYYY-MM-DD') WHERE forecast_date IS NULL;"
#         data = {"table": AsIs(table_name), "forecast_date": forecast_date}
#         curs.execute(query, data)
#         conn.commit()
#
#         # create entry in mosaic table (for geoserver to work)
#         if new_table:
#             query = """
#               CREATE TABLE IF NOT EXISTS mosaic(
#               name text,
#               tiletable text,
#               minx float,
#               miny float,
#               maxx float,
#               maxy float,
#               resx float,
#               resy float);"""
#             curs.execute(query)
#             conn.commit()
#
#             query = "DELETE FROM mosaic WHERE tiletable = %s"
#             curs.execute(query, [table_name])
#             conn.commit()
#
#             query = """
#               INSERT INTO mosaic (name, tiletable, minx, miny, maxx, maxy, resx, resy)
#               VALUES (%s, %s, %s, %s, %s, %s, %s, %s);"""
#             if resolution == '4k':
#                 data = (table_name, table_name, -125, 49.9166666666687, -66.9, 24.2, 0.04166666666667, 0.04166666666667)
#             elif resolution == '2.5k':
#                 data = (table_name, table_name, -2764486.928, -265060.521, 2683176.007, 3232110.510, 2539.703000000000000, 2539.703000000000000)
#             curs.execute(query, data)
#             conn.commit()


if __name__ == "__main__":
    download_forecast()
    extract_bands()
    # warp_to_prism()
    # postgis_import()
