from datetime import datetime, timedelta
from util.raster import *
from util.database import *
import numpy as np
from datetime import date
import logging


with open(os.path.abspath(os.path.join(os.path.dirname(__file__), os.path.pardir, 'config.yml')), 'r') as ymlfile:
    cfg = yaml.load(ymlfile)
    save_path = cfg["avg_agdd_path"]

agdd_avg_table = 'prism_30yr_avg_agdd'


def import_agdd_anomalies(anomaly_date):
    logging.info('importing agdd anomalies')
    save_path = cfg["agdd_anomaly_path"]
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    first_day_of_year = date(anomaly_date.year, 1, 1)
    day = first_day_of_year
    delta = timedelta(days=1)

    agdd_table_name = 'agdd_' + anomaly_date.strftime("%Y")
    agdd_anomaly_table_name = 'agdd_anomaly_' + anomaly_date.strftime("%Y")

    new_table = not table_exists(agdd_anomaly_table_name)

    (rast_cols, rast_rows, transform, projection, no_data_value) = get_raster_info(agdd_table_name, first_day_of_year)

    while day <= anomaly_date:
        day_of_year = day.timetuple().tm_yday
        today = datetime.today().date()

        # skip if agdd anomaly has already been computed and is older than 3 days
        # (otherwise recompute it, because newer tmin/tmax files get updated nightly)
        # if not new_table and day < (today - timedelta(days=3)) and row_exists(agdd_anomaly_table_name, day):
        #     continue

        agdd = get_raster_array(agdd_table_name, 'rast_date', day.strftime("%Y-%m-%d"))
        av_agdd = get_raster_array(agdd_avg_table, 'filename', 'agdd_' + str(day_of_year) + '.tif')

        if agdd is None:
            logging.warning('skipping - could not get agdd for date: %s', day.strftime("%Y-%m-%d"))
            day += delta
            continue

        if av_agdd is None:
            logging.warning('skipping - could not get av_agdd for day of year: %s', str(day_of_year))
            day += delta
            continue

        diff_agdd = agdd - av_agdd
        diff_agdd[diff_agdd == np.nan] = -9999

        # write the raster to disk and import it to the database
        file_name = 'agdd_anomaly_' + day.strftime("%Y%m%d") + '.tif'
        file_path = save_path + file_name
        write_raster(file_path, diff_agdd, no_data_value, rast_cols, rast_rows, projection, transform)
        save_raster_to_postgis(file_path, agdd_anomaly_table_name, 4269)
        set_date_column(agdd_anomaly_table_name, day, new_table)
        update_time_series('agdd_anomaly', file_name, day)
        new_table = False
        logging.info('populated adgg anomaly for %s based on historical addg average for doy %s', day.strftime("%Y-%m-%d"), str(day_of_year))

        day += delta


def import_agdd(agdd_date):
    logging.info('importing agdds')
    save_path = cfg["agdd_path"]
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    agdd_table_name = 'agdd_' + agdd_date.strftime("%Y")
    tmin_table_name = 'tmin_' + agdd_date.strftime("%Y")
    tmax_table_name = 'tmax_' + agdd_date.strftime("%Y")

    first_day_of_year = date(agdd_date.year, 1, 1)
    day = first_day_of_year
    delta = timedelta(days=1)

    new_table = not table_exists(agdd_table_name)

    (rast_cols, rast_rows, transform, projection, no_data_value) = get_raster_info(tmin_table_name, first_day_of_year)

    while day <= agdd_date:

        today = datetime.today().date()
        # skip if agdd has already been computed and is older than 3 days
        # (otherwise recompute it, because newer tmin/tmax files get updated nightly)
        if not new_table and day < (today - timedelta(days=3)) and row_exists(agdd_table_name, day):
            day += delta
            continue

        # only need to get previous days gdd if it's not Jan 1st
        if day != first_day_of_year:
            previous_day = day - delta
            previous_day_agdd = get_raster_array(agdd_table_name, 'rast_date', previous_day.strftime("%Y-%m-%d"))
            if previous_day_agdd is None:
                logging.warning('skipping - could not get agdd for date: %s', previous_day.strftime("%Y-%m-%d"))
                day += delta
                continue

        # compute gdd
        try:
            tmin = get_climate_data(tmin_table_name, day)
            tmax = get_climate_data(tmax_table_name, day)
            if tmin is None:
                logging.warning('skipping - could not get tmin for date: %s', day.strftime("%Y-%m-%d"))
                day += delta
                continue

            if tmax is None:
                logging.warning('skipping - could not get tmax for date: %s', day.strftime("%Y-%m-%d"))
                day += delta
                continue

            gdd = (tmin + tmax) / 2 - 32
            gdd[gdd < 0] = 0

            # compute agdd
            if day != first_day_of_year:
                agdd = previous_day_agdd + gdd
            else:
                agdd = gdd

            # replace no data values
            agdd[agdd == np.nan] = -9999

            # write the raster to disk and import it to the database
            file_name = 'agdd_' + day.strftime("%Y%m%d") + '.tif'
            file_path = save_path + file_name
            write_raster(file_path, agdd, no_data_value, rast_cols, rast_rows, projection, transform)
            save_raster_to_postgis(file_path, agdd_table_name, 4269)
            set_date_column(agdd_table_name, day, new_table)
            update_time_series('agdd', file_name, day)
            new_table = False
            logging.info('populated adgg for %s', day.strftime("%Y-%m-%d"))
        except():
            logging.error('skipping - could not compute agdd for date: %s due to an exception', day.strftime("%Y-%m-%d"))

        day += delta


def import_average_agdd(first_year, last_year):
    logging.info('importing average agdds')
    (rast_cols, rast_rows, transform, projection, no_data_value) = get_raster_info('prism_tmin_2000', datetime(2000, 1, 1))
    agdd = np.zeros((last_year - first_year, rast_rows, rast_cols))
    for day_of_year in range(1,366):
        logging.info('doy: %s', str(day_of_year))
        years_accumulated = 0
        total_over_years = np.zeros((rast_rows, rast_cols))
        for year in range(first_year, last_year):
            year_idx = year - first_year
            logging.info('year: %s', str(year))
            try:
                date_from_doy = date(year, 1, 1) + timedelta(day_of_year - 1)
                logging.info('date_from_doy: %s', date_from_doy.strftime("%Y-%m-%d"))
                tmin_table_name = 'prism' + "_" + 'tmin' + "_" + date_from_doy.strftime("%Y")
                tmax_table_name = 'prism' + "_" + 'tmax' + "_" + date_from_doy.strftime("%Y")
                tmin = get_climate_data(tmin_table_name, date_from_doy)
                tmax = get_climate_data(tmax_table_name, date_from_doy)

                gdd = (tmin + tmax) / 2 - 32
                gdd[gdd < 0] = 0

                if agdd[year_idx] == None:
                    agdd[year_idx] = gdd
                else:
                    agdd[year_idx] += gdd
                total_over_years += agdd[year_idx]
                years_accumulated += 1
            except():
                logging.error('skipping - could not compute agdd average for year: %s (doy: %s)' ,str(year), str(day_of_year))
        average_agdd = total_over_years / years_accumulated

        prewarped_file_path = save_path + 'agdd_unwarped_' + str(day_of_year) + '.tif'
        postwarped_file_path = save_path + 'agdd_' + str(day_of_year) + '.tif'
        os.makedirs(os.path.dirname(postwarped_file_path), exist_ok=True)
        write_raster(prewarped_file_path, average_agdd, no_data_value, rast_cols, rast_rows, projection, transform)

        warp_to_rtma_resolution(prewarped_file_path, postwarped_file_path)
        os.remove(prewarped_file_path)

        save_raster_to_postgis(postwarped_file_path, agdd_avg_table, 4269)
        logging.info('populated average adgg for day of year: %s', str(day_of_year))


def warp_to_rtma_resolution(source_file, dest_file):
    warp_command = "gdalwarp -r bilinear -ts 2606 1228 {source_file} {dest_file}"\
        .format(source_file=source_file, dest_file=dest_file)
    ps = subprocess.Popen(warp_command, stdout=subprocess.PIPE, shell=True)
    ps.wait()


def get_raster_info(table_name, date):
    vsipath = '/vsimem/from_postgis'

    curs = conn.cursor()

    query = "SELECT ST_AsGDALRaster(ST_Union(rast), 'Gtiff') FROM %s WHERE rast_date = %s;"
    data = (AsIs(table_name), date.strftime("%Y-%m-%d"))
    curs.execute(query, data)

    gdal.FileFromMemBuffer(vsipath, bytes(curs.fetchone()[0]))
    curs.close()

    # Read first band of raster with GDAL
    ds = gdal.Open(vsipath)
    band = ds.GetRasterBand(1)

    # Grab all the info to return
    num_cols = ds.RasterXSize
    num_rows = ds.RasterYSize
    transform = ds.GetGeoTransform()
    projection = ds.GetProjection()
    no_data_value = band.GetNoDataValue()

    # Close and clean up virtual memory file
    gdal.Unlink(vsipath)

    return (num_cols, num_rows, transform, projection, no_data_value)


def get_climate_data(table_name, date):
    outarray = get_raster_array(table_name, 'rast_date', date.strftime("%Y-%m-%d"))

    if outarray is None:
        return outarray

    # convert to fahrenheit
    outarray *= 1.8
    outarray += 32

    return outarray


def get_raster_array(table_name, column_name, value):
    # Load raster from postgis into a virtual memory file
    vsipath = '/vsimem/from_postgis'

    curs = conn.cursor()

    query = "SELECT ST_AsGDALRaster(ST_Union(rast), 'Gtiff') FROM %s WHERE %s = %s;"
    data = (AsIs(table_name), AsIs(column_name), value)
    curs.execute(query, data)

    result = curs.fetchone()[0]

    if result is None:
        return None

    gdal.FileFromMemBuffer(vsipath, bytes(result))
    curs.close()

    # Read first band of raster with GDAL
    ds = gdal.Open(vsipath)
    band = ds.GetRasterBand(1)

    outarray = band.ReadAsArray()

    # Close and clean up virtual memory file
    gdal.Unlink(vsipath)

    # convert -9999 values to not a number so we don't have to worry about manipulating them
    outarray[outarray == -9999.0] = np.nan

    return outarray
