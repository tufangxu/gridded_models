from datetime import datetime, timedelta
from util.raster import *
from util.database import *
import numpy as np
from datetime import date
import logging


def populate_six_30yr_average(phenophase):
    logging.info(' ')
    logging.info('------------populating spring index 30yr average for %s-----------------', phenophase)
    save_path = cfg["avg_six_path"] + 'six_30yr_average_' + phenophase + os.sep
    os.makedirs(os.path.dirname(save_path), exist_ok=True)

    historic_six_table = 'prism_spring_index'
    six_avg_table_name = 'prism_30yr_avg_spring_index'
    six_avg_array = None

    count = 0
    for year in range(1981, 2011):
        query = """
          SELECT ST_AsGDALRaster(ST_Union(rast), 'Gtiff')
          FROM %s
          WHERE plant = 'average' AND rast_date = %s AND phenophase = %s;"""
        data = (AsIs(historic_six_table), str(year)+'-01-01', phenophase)
        result_array = get_raster_from_query(query, data)
        if result_array is None:
            logging.error("Couldn't retrieve spring index for year %s", str(year))
            return

        if count is 0:
            (rast_cols, rast_rows, transform, projection, no_data_value) = get_raster_info_from_query(query, data)

        if six_avg_array is None:
            six_avg_array = result_array
        else:
            six_avg_array = six_avg_array + result_array
        count += 1
    six_avg_array /= count
    # six_avg_array[six_avg_array == 0] = -9999
    six_avg_array[six_avg_array <= 0] = -9999

    # for each doy mask out six values greater than doy and then save the raster and import it to the database
    # because of the nature of the masking we work backwards over the day of year
    for day_of_year in range(365, 0, -1):
        six_avg_array[six_avg_array > day_of_year] = -9999

        # write the raster to disk and import it to the database
        prewarped_file_path = save_path + "six_average_unwarped_{phenophase}_{doy}.tif".format(phenophase=phenophase, doy=day_of_year)
        postwarped_file_path = save_path + "six_average_{phenophase}_{doy}.tif".format(phenophase=phenophase, doy=day_of_year)

        write_raster(prewarped_file_path, six_avg_array, no_data_value, rast_cols, rast_rows, projection, transform)

        warp_to_rtma_resolution(prewarped_file_path, postwarped_file_path)
        os.remove(prewarped_file_path)

        save_raster_to_postgis(postwarped_file_path, six_avg_table_name, 4269)
        logging.info('populated average six %s for day of year: %s', phenophase, str(day_of_year))


# def get_30yr_average():
#     return ""
#
#
# def import_six_anomalies(anomaly_date):
#     logging.info(' ')
#     logging.info('-----------------populating spring index anomalies-----------------')
#     save_path = cfg["six_anomaly_path"]
#     os.makedirs(os.path.dirname(save_path), exist_ok=True)
#
#     first_day_of_year = date(anomaly_date.year, 1, 1)
#     day = first_day_of_year
#     delta = timedelta(days=1)
#
#     # TODO
#     av_six = get_30yr_average()
#     # av_six = get_raster_array(agdd_avg_table, 'filename', 'agdd_' + str(day_of_year) + '.tif')
#     if av_six is None:
#         logging.warning('skipping - could not get av_agdd for day of year: %s', str(day_of_year))
#         day += delta
#         return
#
#     phenophase = 'leaf'
#     six_table_name = 'ncep_spring_index'
#     six_anomaly_table_name = 'six_{phenophase}_anomaly'.format(phenophase = phenophase)
#
#     new_table = not table_exists(six_anomaly_table_name)
#
#     (rast_cols, rast_rows, transform, projection, no_data_value) = get_raster_info(six_table_name, first_day_of_year)
#
#     while day <= anomaly_date:
#         day_of_year = day.timetuple().tm_yday
#         today = datetime.today().date()
#
#         #can't see more than a week into the future
#         if day > (today + timedelta(days=8)):
#             day += delta
#             continue
#
#         # skip if agdd anomaly has already been computed and is older than 3 days
#         # (otherwise recompute it, because newer tmin/tmax files get updated nightly)
#         if not new_table and day < (today - timedelta(days=3)) and row_exists(six_anomaly_table_name, day):
#             # logging.info('skipping day %s because it already exists', day.strftime("%Y-%m-%d"))
#             day += delta
#             continue
#
#         six = get_raster_array(six_table_name, 'rast_date', day.strftime("%Y-%m-%d"))
#
#         if six is None:
#             logging.warning('skipping - could not get agdd for date: %s', day.strftime("%Y-%m-%d"))
#             day += delta
#             continue
#
#         diff_six = six - av_six
#         diff_six[diff_six == np.nan] = -9999
#
#         # write the raster to disk and import it to the database
#         file_name = 'agdd_anomaly_' + day.strftime("%Y%m%d") + '.tif'
#         file_path = save_path + file_name
#         write_raster(file_path, diff_six, no_data_value, rast_cols, rast_rows, projection, transform)
#         save_raster_to_postgis(file_path, six_anomaly_table_name, 4269)
#         set_date_column(six_anomaly_table_name, day, new_table)
#         update_time_series('agdd_anomaly', file_name, day)
#         new_table = False
#         logging.info('populated agdd anomaly for %s based on historical agdd average for doy %s', day.strftime("%Y-%m-%d"), str(day_of_year))
#
#         day += delta


#calculate doy based on input date
# geteach years historic
# average them
# set values < doy to 0 in av
# get map for input date
# set values < doy to 0 in map
# map - av
# save and store
